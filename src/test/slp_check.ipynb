{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Check the single layer perceptron implementation\n",
    "import sklearn.neural_network as ann\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048854660886996616"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def genR(N):\n",
    "    return np.random.random(N)*2-1\n",
    "\n",
    "def genF(N):\n",
    "    return np.arange(N)/N+0.001*(genR(N))\n",
    "\n",
    "N = 20\n",
    "Ntrain = 5\n",
    "P = 2\n",
    "features = np.row_stack([genF(N), genF(N)])\n",
    "        ##genF(N), genF(N), genF(N),\n",
    "        ##                 genF(N), genF(N), genF(N), genF(N),\n",
    "        ##                 genF(N), genF(N), genF(N)])\n",
    "beta = 0.1*genR(P)\n",
    "outputs = np.dot(beta, features)\n",
    "\n",
    "np.savetxt('test_features.dat', features, delimiter='\\n')\n",
    "np.savetxt('test_outputs.dat', outputs, delimiter='\\n')\n",
    "\n",
    "hidden_layer_sizes = (10,)\n",
    "activation = 'logistic'\n",
    "solver = 'lbfgs'\n",
    "alpha = 0.0\n",
    "\n",
    "slp = ann.MLPRegressor(hidden_layer_sizes, activation,\n",
    "                       solver, alpha)\n",
    "\n",
    "slp.fit(features.T[:Ntrain], outputs[:Ntrain])\n",
    "\n",
    "predictions = slp.predict(features.T)\n",
    "np.sum((predictions-outputs)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.40961001,  0.39124777, -0.17559302,  0.38904001,  0.31243633,\n",
       "        0.1824043 ,  0.04498684, -0.34695698, -0.72726788, -0.186607  ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(features[0], features[1], outputs)\n",
    "ax.scatter(features[0], features[1], predictions, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00343272235"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5*(-2.24903e-05+0.000649785+0.00139293+0.0020491+0.00279612)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003119075"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5*(0.00139293+0.0020491+0.00279612)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
